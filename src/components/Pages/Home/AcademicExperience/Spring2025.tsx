export const Spring2025Experience = () => {
    return (
        <div>
            <b>Bilkent University</b> <br />
            Teaching Assistant - CS101  Algorithms and Programming I <br />
            Teaching Assistant - CS223 Digital Design <br /><br />

            <b>Community Service</b> <br />
            IEEE Transactions on Computational Biology and Bioinformatics (TCBB) - Reviewer <br />
            Research in Computational Molecular Biology (RECOMB) - Speaker <br /> 
            Intelligent Systems for Molecular Biology (ISMB) Conference - Reviewer <br /><br />

            <b>Papers</b> <br />
            Generated Data with Fake Privacy: Hidden Dangers of Fine-tuning Large Language Models on Generated Data <br/>
            Authors: <i>Akkus A, Poorghaﬀar Aghdam M, Li M, Chu J, Backes M, Zhang Y, Sav S.</i> <br/>
            Fine-tuning large language models (LLMs) with generated data is often considered a privacy-preserving alternative to real data,
            but our study reveals significant privacy risks. We evaluate Personal Information Identifier (PII) leakage and Membership Inference
            Attacks (MIAs) on the Pythia Model Suite and Open Pre-trained Transformer (OPT), finding that fine-tuning with generated data
            can increase privacy vulnerabilities. <br/>
            <i>USENIX Security’25</i> · <a href={"https://usenix.org/conference/usenixsecurity25/presentation/akkus"} target={"_blank"}>https://usenix.org/conference/usenixsecurity25/presentation/akkus</a><br/>
        </div>
    )
}
